{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foetal = sc.read_h5ad(\"/home/andreafabbricatore/thesis/data/foetal_filtered.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC = sc.read_h5ad(\"/home/andreafabbricatore/thesis/data/PBMC.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC = sc.read_h5ad(\"/home/andreafabbricatore/thesis/data/PIC.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia = sc.read_h5ad(\"/home/andreafabbricatore/thesis/data/scsHypoxia_filtered.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foetal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foetal.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foetal.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object contains 4504 cells, each with 29680 genes and their respective counts. In the obs dataframe we can find two types of labels for the data: 'Label' which is the cell subtype adn 'Label_merged' which is the cell-type (macro with respect to the former)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foetal_cell_type_labels = foetal.obs['Label_merged'].tolist()\n",
    "foetal_cell_subtype_labels = foetal.obs['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foetal.obs['Label'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PBMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC.obs['sample'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object contains 14039 cells, each with 12762 genes and their respective counts. In the obs dataframe we can find the 'Label' column which represents the cell-type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC_cell_type_labels = PBMC.obs['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC.obs['Label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object contains 6321 cells, each with 34363 genes and their respective counts. In the obs dataframe we can find the 'Label' column which represents the cell-type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC_cell_type_labels = PIC.obs['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC.obs['Label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypoxia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object contains 9324 cells, each with 19046 genes and their respective counts. In the obs dataframe we can find two types of labels for the data: 'Label' which is the cell-state and 'HypoxicState' which is the cell-type (Hypoxia or Normoxia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia_cell_state_labels = hypoxia.obs['Label'].tolist()\n",
    "hypoxia_cell_labels = hypoxia.obs['HypoxicState'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia.obs['Label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the binning procedure, same as the scGPT one. We won't use it just yet, actually we will train the model on the binned version and not binned version for the benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_is_raw = False\n",
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    #filter_gene_by_counts=filter_gene_by_counts,  # step 1\n",
    "    #filter_cell_by_counts=False,  # step 2\n",
    "    normalize_total=1e4,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=data_is_raw,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=False,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=51,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor(foetal, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor(PBMC, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor(PIC, batch_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor(hypoxia, batch_key=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now produce the labels for each dataset. First, let's encode the labels into categorical variables for our xgboost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foetal_cell_type_labels = labelencoder.fit_transform(foetal_cell_type_labels)\n",
    "foetal_cell_subtype_labels = labelencoder.fit_transform(foetal_cell_subtype_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC_cell_type_labels = labelencoder.fit_transform(PBMC_cell_type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC_cell_type_labels = labelencoder.fit_transform(PIC_cell_type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia_cell_state_labels = labelencoder.fit_transform(hypoxia_cell_state_labels)\n",
    "hypoxia_cell_labels = labelencoder.fit_transform(hypoxia_cell_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder.fit(hypoxia_cell_state_labels)\n",
    "le_name_mapping = dict(zip(labelencoder.classes_, labelencoder.transform(labelencoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ohe_matrix(labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    label_matrix = np.zeros((len(labels), len(unique_labels)))\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        label_matrix[i, label] = 1\n",
    "\n",
    "    return label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foetal_cell_type_labels_matrix = create_ohe_matrix(foetal_cell_type_labels)\n",
    "foetal_cell_subtype_labels_matrix = create_ohe_matrix(foetal_cell_subtype_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBMC_cell_type_labels_matrix = create_ohe_matrix(PBMC_cell_type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIC_cell_type_labels_matrix = create_ohe_matrix(PIC_cell_type_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypoxia_cell_state_labels_matrix = create_ohe_matrix(hypoxia_cell_state_labels)\n",
    "hypoxia_cell_labels_matrix = create_ohe_matrix(hypoxia_cell_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(foetal.layers['X_binned'], foetal_cell_type_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(foetal_cell_type_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(foetal.layers['X_binned'], foetal_cell_subtype_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(foetal_cell_subtype_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(foetal.X, foetal_cell_type_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(foetal_cell_type_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(foetal.X, foetal_cell_subtype_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(foetal_cell_subtype_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(PBMC.layers['X_binned'], PBMC_cell_type_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(PBMC_cell_type_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(PBMC.X, PBMC_cell_type_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(PBMC_cell_type_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(PIC.layers['X_binned'], PIC_cell_type_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(PIC_cell_type_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(PIC.X, PIC_cell_type_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(PIC_cell_type_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hypoxia.layers['X_binned'], hypoxia_cell_state_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(hypoxia_cell_state_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "total = 0\n",
    "for i,j in enumerate(y_test):\n",
    "    if j < 4:\n",
    "        total += 1\n",
    "        if j == preds[i]:\n",
    "            counter += 1\n",
    "\n",
    "print(counter/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hypoxia.X, hypoxia_cell_state_labels, test_size=0.2, random_state=42)\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(hypoxia_cell_state_labels)))\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "total = 0\n",
    "for i,j in enumerate(y_test):\n",
    "    if j < 4:\n",
    "        total += 1\n",
    "        if j == preds[i]:\n",
    "            counter += 1\n",
    "\n",
    "print(counter/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_data, train_labels, num_epochs, learning_rate, convergence_threshold=1e-5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_data = train_data.to(device)\n",
    "    train_labels = train_labels.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    prev_loss = float('inf')  # Initialize with a large value\n",
    "    for epoch in range(num_epochs):\n",
    "        logits = model.forward(train_data)\n",
    "        loss = criterion(logits, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "        # Check convergence\n",
    "        if abs(prev_loss - loss.item()) < convergence_threshold:\n",
    "            print(f'Converged at epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "            break\n",
    "        \n",
    "        prev_loss = loss.item()\n",
    "\n",
    "def validate_model(model, test_data, test_labels):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    test_data = test_data.to(device)\n",
    "    test_labels = test_labels.to(device)\n",
    "    outputs = model(test_data)\n",
    "    _, outputs = torch.max(outputs, dim=1)\n",
    "    _, labels = torch.max(test_labels, dim=1)\n",
    "    # count = 0\n",
    "    # total = 0\n",
    "    # for i,j in enumerate(labels):\n",
    "    #     if j < 4:\n",
    "    #         total += 1\n",
    "    #         if j == outputs[i]:\n",
    "    #             count += 1\n",
    "    # print(len(outputs))\n",
    "    # print(total)\n",
    "    # print(f\"Accuracy: {count/total}\")\n",
    "    print(f\"Accuracy: {accuracy_score(labels, outputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(foetal.layers['X_binned'], foetal_cell_type_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(foetal_cell_type_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(foetal.layers['X_binned'], foetal_cell_subtype_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(foetal_cell_subtype_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(foetal.X, foetal_cell_type_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(foetal_cell_type_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(foetal.X, foetal_cell_subtype_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(foetal_cell_subtype_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(PBMC.layers['X_binned'], PBMC_cell_type_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(PBMC_cell_type_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(PBMC.X, PBMC_cell_type_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(PBMC_cell_type_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(PIC.layers['X_binned'], PIC_cell_type_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(PIC_cell_type_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(PIC.X, PIC_cell_type_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(PIC_cell_type_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hypoxia.layers['X_binned'], hypoxia_cell_state_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(hypoxia_cell_state_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_model(model, test_input_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NON BINNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hypoxia.X, hypoxia_cell_state_labels_matrix, test_size=0.2, random_state=42)\n",
    "# Convert data to PyTorch tensors\n",
    "train_input_data = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=torch.float32)\n",
    "test_input_data = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=torch.float32)\n",
    "# Define hyperparameters\n",
    "input_size = X_train.shape[1]\n",
    "output_size = len(np.unique(hypoxia_cell_state_labels))\n",
    "num_epochs = 5000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the model\n",
    "model = Classifier(input_size, output_size)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_input_data, train_labels, num_epochs, learning_rate)\n",
    "validate_model(model, test_input_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
